{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"YOUR KEY HERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from llm.llm import BedRockLLMs,CoreLLMs\n",
    "from llm.llm_utils import *\n",
    "import numpy as np\n",
    "from pyvi import ViTokenizer\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from prompts import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CoreLLMs(quantization='int4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'bkai-foundation-models/vietnamese-bi-encoder'\n",
    "embd = SentenceTransformerEmbeddings(model_name=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"data_raw10k\"\n",
    "persist_dir=\"/content/drive/MyDrive/speech/RAG/ChromaDB/chromadb\"\n",
    "col_name=\"wiki10k\"\n",
    "DATA_DIR = data_dir\n",
    "CHROMA_PATH = persist_dir\n",
    "COLLECTION_NAME = col_name\n",
    "\n",
    "vectorstore1 = Chroma(collection_name=COLLECTION_NAME, persist_directory=CHROMA_PATH, embedding_function=embd)\n",
    "\n",
    "data_dir=\"gendata\"\n",
    "persist_dir=\"/content/drive/MyDrive/speech/RAG/ChromaDB/genchromadb\"\n",
    "col_name=\"wiki10k\"\n",
    "DATA_DIR = data_dir\n",
    "CHROMA_PATH = persist_dir\n",
    "COLLECTION_NAME = col_name\n",
    "\n",
    "vectorstore2 = Chroma(collection_name=COLLECTION_NAME, persist_directory=CHROMA_PATH, embedding_function=embd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context function\n",
    "def RAG(questions):\n",
    "    data = vectorstore1.similarity_search(questions,5)\n",
    "    context = '\\n\\n'.join([doc.page_content for doc in data])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load questions\n",
    "questions = json.loads(open('/content/drive/MyDrive/speech/RAG/hard_questions_4000.json').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "labels = []\n",
    "predicts = []\n",
    "for test in tqdm(questions[:400]):\n",
    "    try:\n",
    "        question = test['question']\n",
    "        context = RAG(question)\n",
    "        response = RAG_QA(llm, question, context, test['choice'])\n",
    "        answer = response[0]\n",
    "        for key, val in answer.items():\n",
    "          if key != 'answer':\n",
    "            key = 'answer'\n",
    "            answer = {}\n",
    "            answer[key] = val\n",
    "        answer['id'] = test['id']\n",
    "        answers.append(answer)\n",
    "        with open('answers_hard_4000_llama3_base.json', 'w') as f:\n",
    "            f.write(json.dumps(answers))\n",
    "        labels.append(test['answer'])\n",
    "        predicts.append(answer['answer'])\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_label = []\n",
    "for label in labels:\n",
    "    try:\n",
    "        label = int(label)\n",
    "        use_label.append(label)\n",
    "    except:\n",
    "        use_label.append(0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "predicts = np.array(predicts)\n",
    "\n",
    "accuracy = np.mean(labels == predicts)\n",
    "print('Accuracy baseline: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG + Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagReranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker_model = 'BAAI/bge-reranker-v2-m3'\n",
    "reranker = FlagReranker(reranker_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ulitity functions for reranking\n",
    "def create_query(query, docs):\n",
    "\n",
    "    if isinstance(query, list):\n",
    "        query = query[0]\n",
    "    if isinstance(docs, str):\n",
    "        docs = [docs]\n",
    "\n",
    "    pairs = []\n",
    "    for doc in docs:\n",
    "        pairs.append([query, doc])\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def rerank(query, docs, k):\n",
    "    pairs = create_query(query, docs)\n",
    "    scores = np.array(reranker.compute_score(pairs))\n",
    "    docs = np.array(docs)\n",
    "\n",
    "    top_k_indices = np.argpartition(scores, -k)[-k:]\n",
    "    top_k_elements = scores[top_k_indices]\n",
    "    # print(top_k_indices)\n",
    "\n",
    "    top_k_indices = top_k_indices[np.argsort(-top_k_elements)]\n",
    "    return docs[top_k_indices].tolist()\n",
    "\n",
    "def RAG_rerank(questions):\n",
    "    data = vectorstore2.similarity_search(questions,25)\n",
    "    data = rerank(questions, [doc.page_content for doc in data], 5)\n",
    "    context = '\\n\\n'.join(data)\n",
    "    return context\n",
    "    # return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "labels = []\n",
    "predicts = []\n",
    "for test in tqdm(questions):\n",
    "    try:\n",
    "        question = test['question']\n",
    "        context = RAG_rerank(question)\n",
    "        response = RAG_QA(llm, question, context, test['choice'])\n",
    "        answer = response[0]\n",
    "        for key, val in answer.items():\n",
    "          if key != 'answer':\n",
    "            key = 'answer'\n",
    "            answer = {}\n",
    "            answer[key] = val\n",
    "        answer['id'] = test['id']\n",
    "\n",
    "        with open('answers_hard_4000_llama3_reranker.json', 'w') as f:\n",
    "            f.write(json.dumps(answers))\n",
    "        labels.append(test['answer'])\n",
    "        predicts.append(answer['answer'])\n",
    "    except Exception as e:\n",
    "        print('Error: ',e)\n",
    "        print(answer)\n",
    "        pass\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_label = []\n",
    "for label in labels:\n",
    "    try:\n",
    "        label = int(label)\n",
    "        use_label.append(label)\n",
    "    except:\n",
    "        use_label.append(0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "predicts = np.array(predicts)\n",
    "\n",
    "accuracy = np.mean(labels == predicts)\n",
    "print('Accuracy rerank: ', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
